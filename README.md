# Customer Sentiment Analysis Dashboard

An end-to-end NLP analytics system for wireless earbud product reviews.
Generates synthetic data, runs sentiment classification, extracts themes and feature correlations, and serves an interactive Streamlit dashboard.

---

## System Architecture

```
sentiment-dashboard/
│
├── data/
│   └── generate_reviews.py     # Synthetic data generator (10 000 reviews)
│
├── src/
│   ├── config.py               # Central config: paths, thresholds, settings
│   ├── preprocessing.py        # Text cleaning pipelines (VADER + TF-IDF)
│   ├── sentiment.py            # Sentiment classification (VADER / DistilBERT)
│   ├── themes.py               # TF-IDF keyword extraction + feature correlation
│   ├── analytics.py            # KPIs, time trends, brand stats, recommendations
│   └── pipeline.py             # Orchestrator: runs all steps, saves outputs
│
├── outputs/                    # Auto-generated by pipeline
│   ├── scored_reviews.parquet  # All reviews with predicted sentiment + scores
│   ├── feature_summary.csv     # Per-feature sentiment correlation stats
│   ├── keyword_summary.csv     # Top keywords per sentiment bucket
│   ├── time_trends.csv         # Daily/monthly sentiment counts + rolling avg
│   └── metrics.json            # Accuracy, KPIs, brand summary, recommendations
│
├── tests/
│   ├── test_data_generation.py # Schema, row counts, value ranges, correlations
│   ├── test_preprocessing.py   # Unit tests for all text cleaning functions
│   ├── test_sentiment.py       # Sentiment scoring, label mapping, evaluation
│   └── test_pipeline.py        # Integration tests for all output files
│
├── app.py                      # Streamlit dashboard (6 tabs)
├── requirements.txt
└── README.md
```

### Data Flow

```
generate_reviews.py
       ↓ (CSV)
preprocessing.py      → clean_vader, clean_tfidf columns
       ↓
sentiment.py          → sentiment_score, predicted_sentiment
       ↓
themes.py             → keyword_summary, feature_summary
       ↓
analytics.py          → KPIs, trends, brand stats, recommendations
       ↓
pipeline.py           → writes all outputs/ files
       ↓
app.py                → reads outputs/ → 6-tab Streamlit dashboard
```

---

## Setup

### Requirements

- Python 3.10+
- `pip` or equivalent

### Installation

```bash
git clone https://github.com/devarchithbatchu/sentiment-dashboard.git
cd sentiment-dashboard

python -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### Run the Pipeline

```bash
# Step 1: Generate 10,000 synthetic reviews
python data/generate_reviews.py

# Step 2: Run NLP pipeline (preprocessing → sentiment → analytics → save outputs)
python -m src.pipeline

# Optional: use DistilBERT instead of VADER (requires: pip install transformers torch)
python -m src.pipeline --model distilbert

# Step 3: Launch dashboard
streamlit run app.py
```

### Run Tests

```bash
pytest tests/ -v
```

---

## Data Generation

`data/generate_reviews.py` builds a realistic, reproducible dataset (`SEED=42`) of 10,000 wireless earbud reviews with the following properties:

| Field | Description |
|---|---|
| `review_id` | Unique identifier (R00001–R10000) |
| `brand` | One of 6 brands with price/quality differentiation |
| `rating` | 1–5 stars, correlated with sentiment (with noise) |
| `review_text` | Templated prose with pro/con variation per sentiment |
| `review_date` | Random date within past 24 months |
| `verified_purchase` | ~78% verified |
| `country` | US (45%), UK (20%), CA (15%), IN (12%), AU (8%) |
| `price_paid` | Per-brand price ranges |
| `return_flag` | Return rate correlated with brand and sentiment |
| `features_mentioned` | Semicolon-separated (no duplicates) |
| `ground_truth_sentiment` | positive / negative / neutral label for evaluation |

**Correlations built in:**
- Battery, ear tip, and pairing complaints → negative bias
- Build quality, noise cancellation, fast charging → positive bias
- UrbanBeats has highest return rate (~18%)
- AirPods Pro has lowest return rate (~4%)

---

## Example Insights (from synthetic data)

| Insight | Value |
|---|---|
| Overall positive sentiment | 76% |
| Top complaint feature | Ear tips (56.8% negative mention rate) |
| Highest return rate | UrbanBeats (18%) |
| Best marketing opportunity | Fast charging (96.5% positive mention rate) |
| Pipeline accuracy vs ground truth | 74.3% (VADER) |
| Full pipeline execution time | ~1.9 seconds |

---

## Swapping in Real Data

To use real reviews instead of synthetic ones:

1. Prepare a CSV at `data/reviews.csv` with the same column schema.
2. The `ground_truth_sentiment` column is optional — the pipeline evaluates it only if present.
3. If your data lacks `features_mentioned`, the feature analysis tab will show no data (the rest of the dashboard still works).
4. Re-run from Step 2: `python -m src.pipeline`

The config file (`src/config.py`) lets you adjust all thresholds, paths, and backend settings without touching source code.

---

## Sentiment Backends

| Backend | Speed | Accuracy | Requirement |
|---|---|---|---|
| VADER (default) | Fast (~10k/sec) | ~74% on this dataset | Included |
| DistilBERT | Slow (GPU: ~500/sec) | Higher on real data | `pip install transformers torch` |

---

## License

MIT
